// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

public enum Spark_TransferStatus: SwiftProtobuf.Enum, Swift.CaseIterable {
  public typealias RawValue = Int
  case initiated // = 0
  case keyTweaked // = 1
  case rRefundSigned // = 2
  case completed // = 3
  case expired // = 4
  case UNRECOGNIZED(Int)

  public init() {
    self = .initiated
  }

  public init?(rawValue: Int) {
    switch rawValue {
    case 0: self = .initiated
    case 1: self = .keyTweaked
    case 2: self = .rRefundSigned
    case 3: self = .completed
    case 4: self = .expired
    default: self = .UNRECOGNIZED(rawValue)
    }
  }

  public var rawValue: Int {
    switch self {
    case .initiated: return 0
    case .keyTweaked: return 1
    case .rRefundSigned: return 2
    case .completed: return 3
    case .expired: return 4
    case .UNRECOGNIZED(let i): return i
    }
  }

  // The compiler won't synthesize support with the UNRECOGNIZED case.
  public static let allCases: [Spark_TransferStatus] = [
    .initiated,
    .keyTweaked,
    .rRefundSigned,
    .completed,
    .expired,
  ]

}

public struct Spark_DepositAddressProof: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var addressSignatures: Dictionary<String,Data> = [:]

  public var proofOfPossessionSignature: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_GenerateDepositAddressRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var signingPublicKey: Data = Data()

  public var identityPublicKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_Address: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var address: String = String()

  public var verifyingKey: Data = Data()

  public var depositAddressProof: Spark_DepositAddressProof {
    get {return _depositAddressProof ?? Spark_DepositAddressProof()}
    set {_depositAddressProof = newValue}
  }
  /// Returns true if `depositAddressProof` has been explicitly set.
  public var hasDepositAddressProof: Bool {return self._depositAddressProof != nil}
  /// Clears the value of `depositAddressProof`. Subsequent reads from it will return its default value.
  public mutating func clearDepositAddressProof() {self._depositAddressProof = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _depositAddressProof: Spark_DepositAddressProof? = nil
}

public struct Spark_GenerateDepositAddressResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var depositAddress: Spark_Address {
    get {return _depositAddress ?? Spark_Address()}
    set {_depositAddress = newValue}
  }
  /// Returns true if `depositAddress` has been explicitly set.
  public var hasDepositAddress: Bool {return self._depositAddress != nil}
  /// Clears the value of `depositAddress`. Subsequent reads from it will return its default value.
  public mutating func clearDepositAddress() {self._depositAddress = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _depositAddress: Spark_Address? = nil
}

public struct Spark_UTXO: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var txid: String = String()

  public var vout: UInt32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_SigningJob: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var signingPublicKey: Data = Data()

  public var rawTx: Data = Data()

  public var signingNonceCommitment: Common_SigningCommitment {
    get {return _signingNonceCommitment ?? Common_SigningCommitment()}
    set {_signingNonceCommitment = newValue}
  }
  /// Returns true if `signingNonceCommitment` has been explicitly set.
  public var hasSigningNonceCommitment: Bool {return self._signingNonceCommitment != nil}
  /// Clears the value of `signingNonceCommitment`. Subsequent reads from it will return its default value.
  public mutating func clearSigningNonceCommitment() {self._signingNonceCommitment = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _signingNonceCommitment: Common_SigningCommitment? = nil
}

public struct Spark_SigningResult: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var publicKeys: Dictionary<String,Data> = [:]

  public var signingNonceCommitments: Dictionary<String,Common_SigningCommitment> = [:]

  public var signatureShares: Dictionary<String,Data> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_NodeSignatureShares: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeID: String = String()

  public var nodeTxSigningResult: Spark_SigningResult {
    get {return _nodeTxSigningResult ?? Spark_SigningResult()}
    set {_nodeTxSigningResult = newValue}
  }
  /// Returns true if `nodeTxSigningResult` has been explicitly set.
  public var hasNodeTxSigningResult: Bool {return self._nodeTxSigningResult != nil}
  /// Clears the value of `nodeTxSigningResult`. Subsequent reads from it will return its default value.
  public mutating func clearNodeTxSigningResult() {self._nodeTxSigningResult = nil}

  public var refundTxSigningResult: Spark_SigningResult {
    get {return _refundTxSigningResult ?? Spark_SigningResult()}
    set {_refundTxSigningResult = newValue}
  }
  /// Returns true if `refundTxSigningResult` has been explicitly set.
  public var hasRefundTxSigningResult: Bool {return self._refundTxSigningResult != nil}
  /// Clears the value of `refundTxSigningResult`. Subsequent reads from it will return its default value.
  public mutating func clearRefundTxSigningResult() {self._refundTxSigningResult = nil}

  public var verifyingKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _nodeTxSigningResult: Spark_SigningResult? = nil
  fileprivate var _refundTxSigningResult: Spark_SigningResult? = nil
}

public struct Spark_NodeSignatures: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeID: String = String()

  public var nodeTxSignature: Data = Data()

  public var refundTxSignature: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_StartDepositTreeCreationRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var identityPublicKey: Data = Data()

  public var onChainUtxo: Spark_UTXO {
    get {return _onChainUtxo ?? Spark_UTXO()}
    set {_onChainUtxo = newValue}
  }
  /// Returns true if `onChainUtxo` has been explicitly set.
  public var hasOnChainUtxo: Bool {return self._onChainUtxo != nil}
  /// Clears the value of `onChainUtxo`. Subsequent reads from it will return its default value.
  public mutating func clearOnChainUtxo() {self._onChainUtxo = nil}

  public var rootTxSigningJob: Spark_SigningJob {
    get {return _rootTxSigningJob ?? Spark_SigningJob()}
    set {_rootTxSigningJob = newValue}
  }
  /// Returns true if `rootTxSigningJob` has been explicitly set.
  public var hasRootTxSigningJob: Bool {return self._rootTxSigningJob != nil}
  /// Clears the value of `rootTxSigningJob`. Subsequent reads from it will return its default value.
  public mutating func clearRootTxSigningJob() {self._rootTxSigningJob = nil}

  public var refundTxSigningJob: Spark_SigningJob {
    get {return _refundTxSigningJob ?? Spark_SigningJob()}
    set {_refundTxSigningJob = newValue}
  }
  /// Returns true if `refundTxSigningJob` has been explicitly set.
  public var hasRefundTxSigningJob: Bool {return self._refundTxSigningJob != nil}
  /// Clears the value of `refundTxSigningJob`. Subsequent reads from it will return its default value.
  public mutating func clearRefundTxSigningJob() {self._refundTxSigningJob = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _onChainUtxo: Spark_UTXO? = nil
  fileprivate var _rootTxSigningJob: Spark_SigningJob? = nil
  fileprivate var _refundTxSigningJob: Spark_SigningJob? = nil
}

public struct Spark_StartDepositTreeCreationResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var treeID: String = String()

  public var rootNodeSignatureShares: Spark_NodeSignatureShares {
    get {return _rootNodeSignatureShares ?? Spark_NodeSignatureShares()}
    set {_rootNodeSignatureShares = newValue}
  }
  /// Returns true if `rootNodeSignatureShares` has been explicitly set.
  public var hasRootNodeSignatureShares: Bool {return self._rootNodeSignatureShares != nil}
  /// Clears the value of `rootNodeSignatureShares`. Subsequent reads from it will return its default value.
  public mutating func clearRootNodeSignatureShares() {self._rootNodeSignatureShares = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _rootNodeSignatureShares: Spark_NodeSignatureShares? = nil
}

public struct Spark_TreeNode: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var id: String = String()

  public var treeID: String = String()

  public var value: UInt64 = 0

  public var parentNodeID: String {
    get {return _parentNodeID ?? String()}
    set {_parentNodeID = newValue}
  }
  /// Returns true if `parentNodeID` has been explicitly set.
  public var hasParentNodeID: Bool {return self._parentNodeID != nil}
  /// Clears the value of `parentNodeID`. Subsequent reads from it will return its default value.
  public mutating func clearParentNodeID() {self._parentNodeID = nil}

  public var nodeTx: Data = Data()

  public var refundTx: Data = Data()

  public var vout: UInt32 = 0

  public var verifyingPublicKey: Data = Data()

  public var ownerIdentityPublicKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _parentNodeID: String? = nil
}

public struct Spark_Split: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var signingPublicKey: Data = Data()

  public var refundSigningJob: Spark_SigningJob {
    get {return _refundSigningJob ?? Spark_SigningJob()}
    set {_refundSigningJob = newValue}
  }
  /// Returns true if `refundSigningJob` has been explicitly set.
  public var hasRefundSigningJob: Bool {return self._refundSigningJob != nil}
  /// Clears the value of `refundSigningJob`. Subsequent reads from it will return its default value.
  public mutating func clearRefundSigningJob() {self._refundSigningJob = nil}

  public var value: UInt64 = 0

  public var vout: UInt32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _refundSigningJob: Spark_SigningJob? = nil
}

public struct Spark_SplitNodeRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeID: String = String()

  public var parentTxSigningJob: Spark_SigningJob {
    get {return _parentTxSigningJob ?? Spark_SigningJob()}
    set {_parentTxSigningJob = newValue}
  }
  /// Returns true if `parentTxSigningJob` has been explicitly set.
  public var hasParentTxSigningJob: Bool {return self._parentTxSigningJob != nil}
  /// Clears the value of `parentTxSigningJob`. Subsequent reads from it will return its default value.
  public mutating func clearParentTxSigningJob() {self._parentTxSigningJob = nil}

  public var splits: [Spark_Split] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _parentTxSigningJob: Spark_SigningJob? = nil
}

public struct Spark_SplitResult: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeID: String = String()

  public var refundTxSigningResult: Spark_SigningResult {
    get {return _refundTxSigningResult ?? Spark_SigningResult()}
    set {_refundTxSigningResult = newValue}
  }
  /// Returns true if `refundTxSigningResult` has been explicitly set.
  public var hasRefundTxSigningResult: Bool {return self._refundTxSigningResult != nil}
  /// Clears the value of `refundTxSigningResult`. Subsequent reads from it will return its default value.
  public mutating func clearRefundTxSigningResult() {self._refundTxSigningResult = nil}

  public var verifyingKey: Data = Data()

  public var userPublicKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _refundTxSigningResult: Spark_SigningResult? = nil
}

public struct Spark_SplitNodeResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var parentNodeID: String = String()

  public var parentTxSigningResult: Spark_SigningResult {
    get {return _parentTxSigningResult ?? Spark_SigningResult()}
    set {_parentTxSigningResult = newValue}
  }
  /// Returns true if `parentTxSigningResult` has been explicitly set.
  public var hasParentTxSigningResult: Bool {return self._parentTxSigningResult != nil}
  /// Clears the value of `parentTxSigningResult`. Subsequent reads from it will return its default value.
  public mutating func clearParentTxSigningResult() {self._parentTxSigningResult = nil}

  public var splitResults: [Spark_SplitResult] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _parentTxSigningResult: Spark_SigningResult? = nil
}

public struct Spark_FinalizeNodeSignaturesRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var intent: Common_SignatureIntent = .creation

  public var nodeSignatures: [Spark_NodeSignatures] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_FinalizeNodeSignaturesResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodes: [Spark_TreeNode] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_PrepareSplitAddressRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeID: String = String()

  public var signingPublicKeys: [Data] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_PrepareSplitAddressResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var addresses: [Spark_Address] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_SecretShareTweak: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var tweak: Data = Data()

  public var proofs: [Data] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_SendLeafKeyTweak: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var leafID: String = String()

  public var secretShareTweak: Spark_SecretShareTweak {
    get {return _secretShareTweak ?? Spark_SecretShareTweak()}
    set {_secretShareTweak = newValue}
  }
  /// Returns true if `secretShareTweak` has been explicitly set.
  public var hasSecretShareTweak: Bool {return self._secretShareTweak != nil}
  /// Clears the value of `secretShareTweak`. Subsequent reads from it will return its default value.
  public mutating func clearSecretShareTweak() {self._secretShareTweak = nil}

  public var pubkeySharesTweak: Dictionary<String,Data> = [:]

  public var secretCipher: Data = Data()

  /// Signature over Sha256(leaf_id||transfer_id||secret_cipher)
  public var signature: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _secretShareTweak: Spark_SecretShareTweak? = nil
}

public struct Spark_SendTransferRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var transferID: String = String()

  public var ownerIdentityPublicKey: Data = Data()

  public var leavesToSend: [Spark_SendLeafKeyTweak] = []

  public var receiverIdentityPublicKey: Data = Data()

  public var expiryTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _expiryTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_expiryTime = newValue}
  }
  /// Returns true if `expiryTime` has been explicitly set.
  public var hasExpiryTime: Bool {return self._expiryTime != nil}
  /// Clears the value of `expiryTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpiryTime() {self._expiryTime = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _expiryTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

public struct Spark_Transfer: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var id: String = String()

  public var senderIdentityPublicKey: Data = Data()

  public var receiverIdentityPublicKey: Data = Data()

  public var status: Spark_TransferStatus = .initiated

  public var totalValue: UInt64 = 0

  public var expiryTime: SwiftProtobuf.Google_Protobuf_Timestamp {
    get {return _expiryTime ?? SwiftProtobuf.Google_Protobuf_Timestamp()}
    set {_expiryTime = newValue}
  }
  /// Returns true if `expiryTime` has been explicitly set.
  public var hasExpiryTime: Bool {return self._expiryTime != nil}
  /// Clears the value of `expiryTime`. Subsequent reads from it will return its default value.
  public mutating func clearExpiryTime() {self._expiryTime = nil}

  public var leaves: [Spark_TransferLeaf] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _expiryTime: SwiftProtobuf.Google_Protobuf_Timestamp? = nil
}

public struct Spark_TransferLeaf: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var leaf: Spark_TreeNode {
    get {return _leaf ?? Spark_TreeNode()}
    set {_leaf = newValue}
  }
  /// Returns true if `leaf` has been explicitly set.
  public var hasLeaf: Bool {return self._leaf != nil}
  /// Clears the value of `leaf`. Subsequent reads from it will return its default value.
  public mutating func clearLeaf() {self._leaf = nil}

  public var secretCipher: Data = Data()

  public var signature: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _leaf: Spark_TreeNode? = nil
}

public struct Spark_SendTransferResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var transfer: Spark_Transfer {
    get {return _transfer ?? Spark_Transfer()}
    set {_transfer = newValue}
  }
  /// Returns true if `transfer` has been explicitly set.
  public var hasTransfer: Bool {return self._transfer != nil}
  /// Clears the value of `transfer`. Subsequent reads from it will return its default value.
  public mutating func clearTransfer() {self._transfer = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _transfer: Spark_Transfer? = nil
}

public struct Spark_QueryPendingTransfersRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var receiverIdentityPublicKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_QueryPendingTransfersResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var transfers: [Spark_Transfer] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_ClaimLeafKeyTweak: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var leafID: String = String()

  public var secretShareTweak: Spark_SecretShareTweak {
    get {return _secretShareTweak ?? Spark_SecretShareTweak()}
    set {_secretShareTweak = newValue}
  }
  /// Returns true if `secretShareTweak` has been explicitly set.
  public var hasSecretShareTweak: Bool {return self._secretShareTweak != nil}
  /// Clears the value of `secretShareTweak`. Subsequent reads from it will return its default value.
  public mutating func clearSecretShareTweak() {self._secretShareTweak = nil}

  public var pubkeySharesTweak: Dictionary<String,Data> = [:]

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _secretShareTweak: Spark_SecretShareTweak? = nil
}

public struct Spark_ClaimTransferTweakKeysRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var transferID: String = String()

  public var ownerIdentityPublicKey: Data = Data()

  public var leavesToReceive: [Spark_ClaimLeafKeyTweak] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_ClaimLeafSigningJob: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var leafID: String = String()

  public var refundTxSigningJob: Spark_SigningJob {
    get {return _refundTxSigningJob ?? Spark_SigningJob()}
    set {_refundTxSigningJob = newValue}
  }
  /// Returns true if `refundTxSigningJob` has been explicitly set.
  public var hasRefundTxSigningJob: Bool {return self._refundTxSigningJob != nil}
  /// Clears the value of `refundTxSigningJob`. Subsequent reads from it will return its default value.
  public mutating func clearRefundTxSigningJob() {self._refundTxSigningJob = nil}

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _refundTxSigningJob: Spark_SigningJob? = nil
}

public struct Spark_ClaimTransferSignRefundsRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var transferID: String = String()

  public var ownerIdentityPublicKey: Data = Data()

  public var signingJobs: [Spark_ClaimLeafSigningJob] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_ClaimLeafSigningResult: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var leafID: String = String()

  public var refundTxSigningResult: Spark_SigningResult {
    get {return _refundTxSigningResult ?? Spark_SigningResult()}
    set {_refundTxSigningResult = newValue}
  }
  /// Returns true if `refundTxSigningResult` has been explicitly set.
  public var hasRefundTxSigningResult: Bool {return self._refundTxSigningResult != nil}
  /// Clears the value of `refundTxSigningResult`. Subsequent reads from it will return its default value.
  public mutating func clearRefundTxSigningResult() {self._refundTxSigningResult = nil}

  public var verifyingKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _refundTxSigningResult: Spark_SigningResult? = nil
}

public struct Spark_ClaimTransferSignRefundsResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var signingResults: [Spark_ClaimLeafSigningResult] = []

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}
}

public struct Spark_AggregateNodesRequest: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var nodeIds: [String] = []

  public var signingJob: Spark_SigningJob {
    get {return _signingJob ?? Spark_SigningJob()}
    set {_signingJob = newValue}
  }
  /// Returns true if `signingJob` has been explicitly set.
  public var hasSigningJob: Bool {return self._signingJob != nil}
  /// Clears the value of `signingJob`. Subsequent reads from it will return its default value.
  public mutating func clearSigningJob() {self._signingJob = nil}

  /// Serves as a temporary identity public key, this should be get from auth process.
  public var ownerIdentityPublicKey: Data = Data()

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _signingJob: Spark_SigningJob? = nil
}

public struct Spark_AggregateNodesResponse: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  public var aggregateSignature: Spark_SigningResult {
    get {return _aggregateSignature ?? Spark_SigningResult()}
    set {_aggregateSignature = newValue}
  }
  /// Returns true if `aggregateSignature` has been explicitly set.
  public var hasAggregateSignature: Bool {return self._aggregateSignature != nil}
  /// Clears the value of `aggregateSignature`. Subsequent reads from it will return its default value.
  public mutating func clearAggregateSignature() {self._aggregateSignature = nil}

  public var verifyingKey: Data = Data()

  public var parentNodeTx: Data = Data()

  public var parentNodeVout: UInt32 = 0

  public var unknownFields = SwiftProtobuf.UnknownStorage()

  public init() {}

  fileprivate var _aggregateSignature: Spark_SigningResult? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark"

extension Spark_TransferStatus: SwiftProtobuf._ProtoNameProviding {
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "TRANSFER_STATUS_INITIATED"),
    1: .same(proto: "TRANSFER_STATUS_KEY_TWEAKED"),
    2: .same(proto: "TRANSFER_STATUSR_REFUND_SIGNED"),
    3: .same(proto: "TRANSFER_STATUS_COMPLETED"),
    4: .same(proto: "TRANSFER_STATUS_EXPIRED"),
  ]
}

extension Spark_DepositAddressProof: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".DepositAddressProof"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "address_signatures"),
    2: .standard(proto: "proof_of_possession_signature"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: &self.addressSignatures) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.proofOfPossessionSignature) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.addressSignatures.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: self.addressSignatures, fieldNumber: 1)
    }
    if !self.proofOfPossessionSignature.isEmpty {
      try visitor.visitSingularBytesField(value: self.proofOfPossessionSignature, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_DepositAddressProof, rhs: Spark_DepositAddressProof) -> Bool {
    if lhs.addressSignatures != rhs.addressSignatures {return false}
    if lhs.proofOfPossessionSignature != rhs.proofOfPossessionSignature {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_GenerateDepositAddressRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GenerateDepositAddressRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "signing_public_key"),
    2: .standard(proto: "identity_public_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.signingPublicKey) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.identityPublicKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.signingPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.signingPublicKey, fieldNumber: 1)
    }
    if !self.identityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.identityPublicKey, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_GenerateDepositAddressRequest, rhs: Spark_GenerateDepositAddressRequest) -> Bool {
    if lhs.signingPublicKey != rhs.signingPublicKey {return false}
    if lhs.identityPublicKey != rhs.identityPublicKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Address: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Address"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "address"),
    2: .standard(proto: "verifying_key"),
    3: .standard(proto: "deposit_address_proof"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.address) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.verifyingKey) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._depositAddressProof) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.address.isEmpty {
      try visitor.visitSingularStringField(value: self.address, fieldNumber: 1)
    }
    if !self.verifyingKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingKey, fieldNumber: 2)
    }
    try { if let v = self._depositAddressProof {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_Address, rhs: Spark_Address) -> Bool {
    if lhs.address != rhs.address {return false}
    if lhs.verifyingKey != rhs.verifyingKey {return false}
    if lhs._depositAddressProof != rhs._depositAddressProof {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_GenerateDepositAddressResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".GenerateDepositAddressResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "deposit_address"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._depositAddress) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._depositAddress {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_GenerateDepositAddressResponse, rhs: Spark_GenerateDepositAddressResponse) -> Bool {
    if lhs._depositAddress != rhs._depositAddress {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_UTXO: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".UTXO"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "txid"),
    2: .same(proto: "vout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.txid) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.vout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.txid.isEmpty {
      try visitor.visitSingularStringField(value: self.txid, fieldNumber: 1)
    }
    if self.vout != 0 {
      try visitor.visitSingularUInt32Field(value: self.vout, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_UTXO, rhs: Spark_UTXO) -> Bool {
    if lhs.txid != rhs.txid {return false}
    if lhs.vout != rhs.vout {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SigningJob: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SigningJob"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "signing_public_key"),
    2: .standard(proto: "raw_tx"),
    3: .standard(proto: "signing_nonce_commitment"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.signingPublicKey) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.rawTx) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._signingNonceCommitment) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.signingPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.signingPublicKey, fieldNumber: 1)
    }
    if !self.rawTx.isEmpty {
      try visitor.visitSingularBytesField(value: self.rawTx, fieldNumber: 2)
    }
    try { if let v = self._signingNonceCommitment {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SigningJob, rhs: Spark_SigningJob) -> Bool {
    if lhs.signingPublicKey != rhs.signingPublicKey {return false}
    if lhs.rawTx != rhs.rawTx {return false}
    if lhs._signingNonceCommitment != rhs._signingNonceCommitment {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SigningResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SigningResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "public_keys"),
    2: .standard(proto: "signing_nonce_commitments"),
    3: .standard(proto: "signature_shares"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: &self.publicKeys) }()
      case 2: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Common_SigningCommitment>.self, value: &self.signingNonceCommitments) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: &self.signatureShares) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.publicKeys.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: self.publicKeys, fieldNumber: 1)
    }
    if !self.signingNonceCommitments.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMessageMap<SwiftProtobuf.ProtobufString,Common_SigningCommitment>.self, value: self.signingNonceCommitments, fieldNumber: 2)
    }
    if !self.signatureShares.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: self.signatureShares, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SigningResult, rhs: Spark_SigningResult) -> Bool {
    if lhs.publicKeys != rhs.publicKeys {return false}
    if lhs.signingNonceCommitments != rhs.signingNonceCommitments {return false}
    if lhs.signatureShares != rhs.signatureShares {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_NodeSignatureShares: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".NodeSignatureShares"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_id"),
    2: .standard(proto: "node_tx_signing_result"),
    3: .standard(proto: "refund_tx_signing_result"),
    4: .standard(proto: "verifying_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.nodeID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._nodeTxSigningResult) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._refundTxSigningResult) }()
      case 4: try { try decoder.decodeSingularBytesField(value: &self.verifyingKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.nodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.nodeID, fieldNumber: 1)
    }
    try { if let v = self._nodeTxSigningResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._refundTxSigningResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.verifyingKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingKey, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_NodeSignatureShares, rhs: Spark_NodeSignatureShares) -> Bool {
    if lhs.nodeID != rhs.nodeID {return false}
    if lhs._nodeTxSigningResult != rhs._nodeTxSigningResult {return false}
    if lhs._refundTxSigningResult != rhs._refundTxSigningResult {return false}
    if lhs.verifyingKey != rhs.verifyingKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_NodeSignatures: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".NodeSignatures"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_id"),
    2: .standard(proto: "node_tx_signature"),
    3: .standard(proto: "refund_tx_signature"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.nodeID) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.nodeTxSignature) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.refundTxSignature) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.nodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.nodeID, fieldNumber: 1)
    }
    if !self.nodeTxSignature.isEmpty {
      try visitor.visitSingularBytesField(value: self.nodeTxSignature, fieldNumber: 2)
    }
    if !self.refundTxSignature.isEmpty {
      try visitor.visitSingularBytesField(value: self.refundTxSignature, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_NodeSignatures, rhs: Spark_NodeSignatures) -> Bool {
    if lhs.nodeID != rhs.nodeID {return false}
    if lhs.nodeTxSignature != rhs.nodeTxSignature {return false}
    if lhs.refundTxSignature != rhs.refundTxSignature {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_StartDepositTreeCreationRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StartDepositTreeCreationRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "identity_public_key"),
    2: .standard(proto: "on_chain_utxo"),
    3: .standard(proto: "root_tx_signing_job"),
    4: .standard(proto: "refund_tx_signing_job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.identityPublicKey) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._onChainUtxo) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._rootTxSigningJob) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._refundTxSigningJob) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.identityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.identityPublicKey, fieldNumber: 1)
    }
    try { if let v = self._onChainUtxo {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._rootTxSigningJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._refundTxSigningJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_StartDepositTreeCreationRequest, rhs: Spark_StartDepositTreeCreationRequest) -> Bool {
    if lhs.identityPublicKey != rhs.identityPublicKey {return false}
    if lhs._onChainUtxo != rhs._onChainUtxo {return false}
    if lhs._rootTxSigningJob != rhs._rootTxSigningJob {return false}
    if lhs._refundTxSigningJob != rhs._refundTxSigningJob {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_StartDepositTreeCreationResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".StartDepositTreeCreationResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "tree_id"),
    2: .standard(proto: "root_node_signature_shares"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.treeID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._rootNodeSignatureShares) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.treeID.isEmpty {
      try visitor.visitSingularStringField(value: self.treeID, fieldNumber: 1)
    }
    try { if let v = self._rootNodeSignatureShares {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_StartDepositTreeCreationResponse, rhs: Spark_StartDepositTreeCreationResponse) -> Bool {
    if lhs.treeID != rhs.treeID {return false}
    if lhs._rootNodeSignatureShares != rhs._rootNodeSignatureShares {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_TreeNode: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TreeNode"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "id"),
    2: .standard(proto: "tree_id"),
    3: .same(proto: "value"),
    4: .standard(proto: "parent_node_id"),
    5: .standard(proto: "node_tx"),
    6: .standard(proto: "refund_tx"),
    7: .same(proto: "vout"),
    8: .standard(proto: "verifying_public_key"),
    9: .standard(proto: "owner_identity_public_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.id) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.treeID) }()
      case 3: try { try decoder.decodeSingularUInt64Field(value: &self.value) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self._parentNodeID) }()
      case 5: try { try decoder.decodeSingularBytesField(value: &self.nodeTx) }()
      case 6: try { try decoder.decodeSingularBytesField(value: &self.refundTx) }()
      case 7: try { try decoder.decodeSingularUInt32Field(value: &self.vout) }()
      case 8: try { try decoder.decodeSingularBytesField(value: &self.verifyingPublicKey) }()
      case 9: try { try decoder.decodeSingularBytesField(value: &self.ownerIdentityPublicKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.id.isEmpty {
      try visitor.visitSingularStringField(value: self.id, fieldNumber: 1)
    }
    if !self.treeID.isEmpty {
      try visitor.visitSingularStringField(value: self.treeID, fieldNumber: 2)
    }
    if self.value != 0 {
      try visitor.visitSingularUInt64Field(value: self.value, fieldNumber: 3)
    }
    try { if let v = self._parentNodeID {
      try visitor.visitSingularStringField(value: v, fieldNumber: 4)
    } }()
    if !self.nodeTx.isEmpty {
      try visitor.visitSingularBytesField(value: self.nodeTx, fieldNumber: 5)
    }
    if !self.refundTx.isEmpty {
      try visitor.visitSingularBytesField(value: self.refundTx, fieldNumber: 6)
    }
    if self.vout != 0 {
      try visitor.visitSingularUInt32Field(value: self.vout, fieldNumber: 7)
    }
    if !self.verifyingPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingPublicKey, fieldNumber: 8)
    }
    if !self.ownerIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.ownerIdentityPublicKey, fieldNumber: 9)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_TreeNode, rhs: Spark_TreeNode) -> Bool {
    if lhs.id != rhs.id {return false}
    if lhs.treeID != rhs.treeID {return false}
    if lhs.value != rhs.value {return false}
    if lhs._parentNodeID != rhs._parentNodeID {return false}
    if lhs.nodeTx != rhs.nodeTx {return false}
    if lhs.refundTx != rhs.refundTx {return false}
    if lhs.vout != rhs.vout {return false}
    if lhs.verifyingPublicKey != rhs.verifyingPublicKey {return false}
    if lhs.ownerIdentityPublicKey != rhs.ownerIdentityPublicKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Split: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Split"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "signing_public_key"),
    2: .standard(proto: "refund_signing_job"),
    3: .same(proto: "value"),
    4: .same(proto: "vout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.signingPublicKey) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._refundSigningJob) }()
      case 3: try { try decoder.decodeSingularUInt64Field(value: &self.value) }()
      case 4: try { try decoder.decodeSingularUInt32Field(value: &self.vout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.signingPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.signingPublicKey, fieldNumber: 1)
    }
    try { if let v = self._refundSigningJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.value != 0 {
      try visitor.visitSingularUInt64Field(value: self.value, fieldNumber: 3)
    }
    if self.vout != 0 {
      try visitor.visitSingularUInt32Field(value: self.vout, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_Split, rhs: Spark_Split) -> Bool {
    if lhs.signingPublicKey != rhs.signingPublicKey {return false}
    if lhs._refundSigningJob != rhs._refundSigningJob {return false}
    if lhs.value != rhs.value {return false}
    if lhs.vout != rhs.vout {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SplitNodeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitNodeRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_id"),
    2: .standard(proto: "parent_tx_signing_job"),
    3: .same(proto: "splits"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.nodeID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._parentTxSigningJob) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.splits) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.nodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.nodeID, fieldNumber: 1)
    }
    try { if let v = self._parentTxSigningJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.splits.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.splits, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SplitNodeRequest, rhs: Spark_SplitNodeRequest) -> Bool {
    if lhs.nodeID != rhs.nodeID {return false}
    if lhs._parentTxSigningJob != rhs._parentTxSigningJob {return false}
    if lhs.splits != rhs.splits {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SplitResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_id"),
    2: .standard(proto: "refund_tx_signing_result"),
    3: .standard(proto: "verifying_key"),
    4: .standard(proto: "user_public_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.nodeID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._refundTxSigningResult) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.verifyingKey) }()
      case 4: try { try decoder.decodeSingularBytesField(value: &self.userPublicKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.nodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.nodeID, fieldNumber: 1)
    }
    try { if let v = self._refundTxSigningResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.verifyingKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingKey, fieldNumber: 3)
    }
    if !self.userPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.userPublicKey, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SplitResult, rhs: Spark_SplitResult) -> Bool {
    if lhs.nodeID != rhs.nodeID {return false}
    if lhs._refundTxSigningResult != rhs._refundTxSigningResult {return false}
    if lhs.verifyingKey != rhs.verifyingKey {return false}
    if lhs.userPublicKey != rhs.userPublicKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SplitNodeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SplitNodeResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "parent_node_id"),
    2: .standard(proto: "parent_tx_signing_result"),
    3: .standard(proto: "split_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.parentNodeID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._parentTxSigningResult) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.splitResults) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.parentNodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.parentNodeID, fieldNumber: 1)
    }
    try { if let v = self._parentTxSigningResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.splitResults.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.splitResults, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SplitNodeResponse, rhs: Spark_SplitNodeResponse) -> Bool {
    if lhs.parentNodeID != rhs.parentNodeID {return false}
    if lhs._parentTxSigningResult != rhs._parentTxSigningResult {return false}
    if lhs.splitResults != rhs.splitResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_FinalizeNodeSignaturesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeNodeSignaturesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "intent"),
    2: .standard(proto: "node_signatures"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.intent) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.nodeSignatures) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.intent != .creation {
      try visitor.visitSingularEnumField(value: self.intent, fieldNumber: 1)
    }
    if !self.nodeSignatures.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.nodeSignatures, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_FinalizeNodeSignaturesRequest, rhs: Spark_FinalizeNodeSignaturesRequest) -> Bool {
    if lhs.intent != rhs.intent {return false}
    if lhs.nodeSignatures != rhs.nodeSignatures {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_FinalizeNodeSignaturesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".FinalizeNodeSignaturesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "nodes"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.nodes) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.nodes.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.nodes, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_FinalizeNodeSignaturesResponse, rhs: Spark_FinalizeNodeSignaturesResponse) -> Bool {
    if lhs.nodes != rhs.nodes {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_PrepareSplitAddressRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".PrepareSplitAddressRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_id"),
    2: .standard(proto: "signing_public_keys"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.nodeID) }()
      case 2: try { try decoder.decodeRepeatedBytesField(value: &self.signingPublicKeys) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.nodeID.isEmpty {
      try visitor.visitSingularStringField(value: self.nodeID, fieldNumber: 1)
    }
    if !self.signingPublicKeys.isEmpty {
      try visitor.visitRepeatedBytesField(value: self.signingPublicKeys, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_PrepareSplitAddressRequest, rhs: Spark_PrepareSplitAddressRequest) -> Bool {
    if lhs.nodeID != rhs.nodeID {return false}
    if lhs.signingPublicKeys != rhs.signingPublicKeys {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_PrepareSplitAddressResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".PrepareSplitAddressResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "addresses"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.addresses) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.addresses.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.addresses, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_PrepareSplitAddressResponse, rhs: Spark_PrepareSplitAddressResponse) -> Bool {
    if lhs.addresses != rhs.addresses {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SecretShareTweak: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SecretShareTweak"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "tweak"),
    2: .same(proto: "proofs"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.tweak) }()
      case 2: try { try decoder.decodeRepeatedBytesField(value: &self.proofs) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tweak.isEmpty {
      try visitor.visitSingularBytesField(value: self.tweak, fieldNumber: 1)
    }
    if !self.proofs.isEmpty {
      try visitor.visitRepeatedBytesField(value: self.proofs, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SecretShareTweak, rhs: Spark_SecretShareTweak) -> Bool {
    if lhs.tweak != rhs.tweak {return false}
    if lhs.proofs != rhs.proofs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SendLeafKeyTweak: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SendLeafKeyTweak"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "leaf_id"),
    2: .standard(proto: "secret_share_tweak"),
    3: .standard(proto: "pubkey_shares_tweak"),
    4: .standard(proto: "secret_cipher"),
    5: .same(proto: "signature"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.leafID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._secretShareTweak) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: &self.pubkeySharesTweak) }()
      case 4: try { try decoder.decodeSingularBytesField(value: &self.secretCipher) }()
      case 5: try { try decoder.decodeSingularBytesField(value: &self.signature) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.leafID.isEmpty {
      try visitor.visitSingularStringField(value: self.leafID, fieldNumber: 1)
    }
    try { if let v = self._secretShareTweak {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.pubkeySharesTweak.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: self.pubkeySharesTweak, fieldNumber: 3)
    }
    if !self.secretCipher.isEmpty {
      try visitor.visitSingularBytesField(value: self.secretCipher, fieldNumber: 4)
    }
    if !self.signature.isEmpty {
      try visitor.visitSingularBytesField(value: self.signature, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SendLeafKeyTweak, rhs: Spark_SendLeafKeyTweak) -> Bool {
    if lhs.leafID != rhs.leafID {return false}
    if lhs._secretShareTweak != rhs._secretShareTweak {return false}
    if lhs.pubkeySharesTweak != rhs.pubkeySharesTweak {return false}
    if lhs.secretCipher != rhs.secretCipher {return false}
    if lhs.signature != rhs.signature {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SendTransferRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SendTransferRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "transfer_id"),
    2: .standard(proto: "owner_identity_public_key"),
    3: .standard(proto: "leaves_to_send"),
    4: .standard(proto: "receiver_identity_public_key"),
    5: .standard(proto: "expiry_time"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transferID) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.ownerIdentityPublicKey) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.leavesToSend) }()
      case 4: try { try decoder.decodeSingularBytesField(value: &self.receiverIdentityPublicKey) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._expiryTime) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.transferID.isEmpty {
      try visitor.visitSingularStringField(value: self.transferID, fieldNumber: 1)
    }
    if !self.ownerIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.ownerIdentityPublicKey, fieldNumber: 2)
    }
    if !self.leavesToSend.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.leavesToSend, fieldNumber: 3)
    }
    if !self.receiverIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.receiverIdentityPublicKey, fieldNumber: 4)
    }
    try { if let v = self._expiryTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SendTransferRequest, rhs: Spark_SendTransferRequest) -> Bool {
    if lhs.transferID != rhs.transferID {return false}
    if lhs.ownerIdentityPublicKey != rhs.ownerIdentityPublicKey {return false}
    if lhs.leavesToSend != rhs.leavesToSend {return false}
    if lhs.receiverIdentityPublicKey != rhs.receiverIdentityPublicKey {return false}
    if lhs._expiryTime != rhs._expiryTime {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Transfer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".Transfer"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "id"),
    2: .standard(proto: "sender_identity_public_key"),
    3: .standard(proto: "receiver_identity_public_key"),
    4: .same(proto: "status"),
    5: .standard(proto: "total_value"),
    6: .standard(proto: "expiry_time"),
    7: .same(proto: "leaves"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.id) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.senderIdentityPublicKey) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.receiverIdentityPublicKey) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.status) }()
      case 5: try { try decoder.decodeSingularUInt64Field(value: &self.totalValue) }()
      case 6: try { try decoder.decodeSingularMessageField(value: &self._expiryTime) }()
      case 7: try { try decoder.decodeRepeatedMessageField(value: &self.leaves) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.id.isEmpty {
      try visitor.visitSingularStringField(value: self.id, fieldNumber: 1)
    }
    if !self.senderIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.senderIdentityPublicKey, fieldNumber: 2)
    }
    if !self.receiverIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.receiverIdentityPublicKey, fieldNumber: 3)
    }
    if self.status != .initiated {
      try visitor.visitSingularEnumField(value: self.status, fieldNumber: 4)
    }
    if self.totalValue != 0 {
      try visitor.visitSingularUInt64Field(value: self.totalValue, fieldNumber: 5)
    }
    try { if let v = self._expiryTime {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    } }()
    if !self.leaves.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.leaves, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_Transfer, rhs: Spark_Transfer) -> Bool {
    if lhs.id != rhs.id {return false}
    if lhs.senderIdentityPublicKey != rhs.senderIdentityPublicKey {return false}
    if lhs.receiverIdentityPublicKey != rhs.receiverIdentityPublicKey {return false}
    if lhs.status != rhs.status {return false}
    if lhs.totalValue != rhs.totalValue {return false}
    if lhs._expiryTime != rhs._expiryTime {return false}
    if lhs.leaves != rhs.leaves {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_TransferLeaf: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".TransferLeaf"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "leaf"),
    2: .standard(proto: "secret_cipher"),
    3: .same(proto: "signature"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._leaf) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.secretCipher) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.signature) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._leaf {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.secretCipher.isEmpty {
      try visitor.visitSingularBytesField(value: self.secretCipher, fieldNumber: 2)
    }
    if !self.signature.isEmpty {
      try visitor.visitSingularBytesField(value: self.signature, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_TransferLeaf, rhs: Spark_TransferLeaf) -> Bool {
    if lhs._leaf != rhs._leaf {return false}
    if lhs.secretCipher != rhs.secretCipher {return false}
    if lhs.signature != rhs.signature {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_SendTransferResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".SendTransferResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "transfer"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._transfer) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._transfer {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_SendTransferResponse, rhs: Spark_SendTransferResponse) -> Bool {
    if lhs._transfer != rhs._transfer {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_QueryPendingTransfersRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".QueryPendingTransfersRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "receiver_identity_public_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.receiverIdentityPublicKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.receiverIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.receiverIdentityPublicKey, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_QueryPendingTransfersRequest, rhs: Spark_QueryPendingTransfersRequest) -> Bool {
    if lhs.receiverIdentityPublicKey != rhs.receiverIdentityPublicKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_QueryPendingTransfersResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".QueryPendingTransfersResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "transfers"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.transfers) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transfers.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.transfers, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_QueryPendingTransfersResponse, rhs: Spark_QueryPendingTransfersResponse) -> Bool {
    if lhs.transfers != rhs.transfers {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimLeafKeyTweak: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimLeafKeyTweak"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "leaf_id"),
    2: .standard(proto: "secret_share_tweak"),
    3: .standard(proto: "pubkey_shares_tweak"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.leafID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._secretShareTweak) }()
      case 3: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: &self.pubkeySharesTweak) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.leafID.isEmpty {
      try visitor.visitSingularStringField(value: self.leafID, fieldNumber: 1)
    }
    try { if let v = self._secretShareTweak {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.pubkeySharesTweak.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufBytes>.self, value: self.pubkeySharesTweak, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimLeafKeyTweak, rhs: Spark_ClaimLeafKeyTweak) -> Bool {
    if lhs.leafID != rhs.leafID {return false}
    if lhs._secretShareTweak != rhs._secretShareTweak {return false}
    if lhs.pubkeySharesTweak != rhs.pubkeySharesTweak {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimTransferTweakKeysRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimTransferTweakKeysRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "transfer_id"),
    2: .standard(proto: "owner_identity_public_key"),
    3: .standard(proto: "leaves_to_receive"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transferID) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.ownerIdentityPublicKey) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.leavesToReceive) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transferID.isEmpty {
      try visitor.visitSingularStringField(value: self.transferID, fieldNumber: 1)
    }
    if !self.ownerIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.ownerIdentityPublicKey, fieldNumber: 2)
    }
    if !self.leavesToReceive.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.leavesToReceive, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimTransferTweakKeysRequest, rhs: Spark_ClaimTransferTweakKeysRequest) -> Bool {
    if lhs.transferID != rhs.transferID {return false}
    if lhs.ownerIdentityPublicKey != rhs.ownerIdentityPublicKey {return false}
    if lhs.leavesToReceive != rhs.leavesToReceive {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimLeafSigningJob: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimLeafSigningJob"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "leaf_id"),
    2: .standard(proto: "refund_tx_signing_job"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.leafID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._refundTxSigningJob) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.leafID.isEmpty {
      try visitor.visitSingularStringField(value: self.leafID, fieldNumber: 1)
    }
    try { if let v = self._refundTxSigningJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimLeafSigningJob, rhs: Spark_ClaimLeafSigningJob) -> Bool {
    if lhs.leafID != rhs.leafID {return false}
    if lhs._refundTxSigningJob != rhs._refundTxSigningJob {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimTransferSignRefundsRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimTransferSignRefundsRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "transfer_id"),
    2: .standard(proto: "owner_identity_public_key"),
    3: .standard(proto: "signing_jobs"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transferID) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.ownerIdentityPublicKey) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.signingJobs) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transferID.isEmpty {
      try visitor.visitSingularStringField(value: self.transferID, fieldNumber: 1)
    }
    if !self.ownerIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.ownerIdentityPublicKey, fieldNumber: 2)
    }
    if !self.signingJobs.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.signingJobs, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimTransferSignRefundsRequest, rhs: Spark_ClaimTransferSignRefundsRequest) -> Bool {
    if lhs.transferID != rhs.transferID {return false}
    if lhs.ownerIdentityPublicKey != rhs.ownerIdentityPublicKey {return false}
    if lhs.signingJobs != rhs.signingJobs {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimLeafSigningResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimLeafSigningResult"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "leaf_id"),
    2: .standard(proto: "refund_tx_signing_result"),
    3: .standard(proto: "verifying_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.leafID) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._refundTxSigningResult) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.verifyingKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.leafID.isEmpty {
      try visitor.visitSingularStringField(value: self.leafID, fieldNumber: 1)
    }
    try { if let v = self._refundTxSigningResult {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.verifyingKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingKey, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimLeafSigningResult, rhs: Spark_ClaimLeafSigningResult) -> Bool {
    if lhs.leafID != rhs.leafID {return false}
    if lhs._refundTxSigningResult != rhs._refundTxSigningResult {return false}
    if lhs.verifyingKey != rhs.verifyingKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_ClaimTransferSignRefundsResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".ClaimTransferSignRefundsResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "signing_results"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.signingResults) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.signingResults.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.signingResults, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_ClaimTransferSignRefundsResponse, rhs: Spark_ClaimTransferSignRefundsResponse) -> Bool {
    if lhs.signingResults != rhs.signingResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_AggregateNodesRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AggregateNodesRequest"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "node_ids"),
    2: .standard(proto: "signing_job"),
    3: .standard(proto: "owner_identity_public_key"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedStringField(value: &self.nodeIds) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._signingJob) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.ownerIdentityPublicKey) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.nodeIds.isEmpty {
      try visitor.visitRepeatedStringField(value: self.nodeIds, fieldNumber: 1)
    }
    try { if let v = self._signingJob {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.ownerIdentityPublicKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.ownerIdentityPublicKey, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_AggregateNodesRequest, rhs: Spark_AggregateNodesRequest) -> Bool {
    if lhs.nodeIds != rhs.nodeIds {return false}
    if lhs._signingJob != rhs._signingJob {return false}
    if lhs.ownerIdentityPublicKey != rhs.ownerIdentityPublicKey {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_AggregateNodesResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  public static let protoMessageName: String = _protobuf_package + ".AggregateNodesResponse"
  public static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "aggregate_signature"),
    2: .standard(proto: "verifying_key"),
    3: .standard(proto: "parent_node_tx"),
    4: .standard(proto: "parent_node_vout"),
  ]

  public mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._aggregateSignature) }()
      case 2: try { try decoder.decodeSingularBytesField(value: &self.verifyingKey) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.parentNodeTx) }()
      case 4: try { try decoder.decodeSingularUInt32Field(value: &self.parentNodeVout) }()
      default: break
      }
    }
  }

  public func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._aggregateSignature {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.verifyingKey.isEmpty {
      try visitor.visitSingularBytesField(value: self.verifyingKey, fieldNumber: 2)
    }
    if !self.parentNodeTx.isEmpty {
      try visitor.visitSingularBytesField(value: self.parentNodeTx, fieldNumber: 3)
    }
    if self.parentNodeVout != 0 {
      try visitor.visitSingularUInt32Field(value: self.parentNodeVout, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  public static func ==(lhs: Spark_AggregateNodesResponse, rhs: Spark_AggregateNodesResponse) -> Bool {
    if lhs._aggregateSignature != rhs._aggregateSignature {return false}
    if lhs.verifyingKey != rhs.verifyingKey {return false}
    if lhs.parentNodeTx != rhs.parentNodeTx {return false}
    if lhs.parentNodeVout != rhs.parentNodeVout {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
